{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69340398-bfd3-4b71-9ea4-20dc0d0ff5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "import langchain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6561931e-a0d5-48b7-a747-8ca530919d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /add your LLM key here (ChatGPT, LLama...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc32d79-354e-4f1a-bcc0-1bd8aa32b665",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m LLM \u001b[38;5;241m=\u001b[39m ChatOpenAI(\n\u001b[1;32m      3\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<recall key name here>\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# temperature=0, [strict and not creative output]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m     stop\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|start_header_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|end_header_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eot_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|reserved_special_token\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ChatOpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "LLM = ChatOpenAI(\n",
    "    name=\"<recall key name here>\",\n",
    "    model=model_name,\n",
    "    # temperature=0, \n",
    "    temperature=1, \n",
    "    stop=[\"<|start_header_id|>\", \"<|end_header_id|>\", \"<|eot_id|>\", \"<|reserved_special_token\"]\n",
    ")\n",
    "\n",
    "# temperature=0 [strict and not creative output]\n",
    "#  temperature=1 [more creative output e.g. more empathic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbed2976-b3d9-4e9d-b6f7-fdb143830a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf2078d0-18ce-47f6-9f61-d3a360fdfd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('YourCV.txt', 'r') as g:\n",
    "    experience = g.read()\n",
    "\n",
    "# In the same folder of your Jupyter Notebook folder, create input document labeled YourCV.txt, containing your most recent CV and other details about your career and professional life in .txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0491db9-e61d-4f18-803f-cc722ea4ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Examples_JobApplications.txt', 'r') as f:\n",
    "    input = f.read()\n",
    "\n",
    "# In the same folder of your Jupyter Notebook folder, create input document labeled Examples_JobApplications.txt, containing examples of your previously written motivational letters in .txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "594e7b64-0e95-4f8d-8528-a24099d74cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added text from https://join.com/companies/omnipeak/13055016-head-of-product-m-f-d?pid=731067c1dfecf6015bf5&oid=1a7e3b62-65e7-44ba-8618-0add298db957\n",
      "All pages have been saved to Website_scraper_text.txt\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"<www.company.com/vacancy>\"\n",
    "    # Add here the URL of the vacancy or job opening you want to apply to\n",
    "]\n",
    "\n",
    "# Filename to save the combined text\n",
    "filename = \"Website_scraper_text.txt\"\n",
    "\n",
    "# Open the file in write mode to clear it if it exists\n",
    "with open(filename, \"w\") as file:\n",
    "    file.write(\"\")  # Start with an empty file\n",
    "\n",
    "# Loop through each URL\n",
    "for url in urls:\n",
    "    try:\n",
    "        # Step 1: Fetch the HTML content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Ensure request was successful\n",
    "        html_content = response.content\n",
    "\n",
    "        # Step 2: Parse the HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        \n",
    "        # Step 3: Extract the text\n",
    "        page_text = soup.get_text()\n",
    "\n",
    "        # Step 4: Append the extracted text to the file\n",
    "        with open(filename, \"a\") as file:\n",
    "            file.write(f\"URL: {url}\\n\")  # Optional: Write URL as a header\n",
    "            file.write(page_text)\n",
    "            file.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")  # Separator between pages\n",
    "\n",
    "        print(f\"Successfully added text from {url}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to retrieve {url}: {e}\")\n",
    "\n",
    "print(f\"All pages have been saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7453ca9b-cfe3-44fa-b41d-c80e3eecb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Website_scraper_text.txt', 'r') as f:\n",
    "    examples = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8687591e-02ea-4b0d-a630-261c47b6c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(examples)\n",
    "\n",
    "# If you want to double-check that the examples are right, then activate this code line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c0d2bd29-99f1-4907-bb09-ff2e66f14d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ApplicationWriter_CompanyContext.txt', 'r') as h:\n",
    "    context = h.read()\n",
    "\n",
    "# 1. Go to ChatGPT, Perplexity, Grok, or any other of your fav genAI platforms.\n",
    "# 2. Ask to run research on the company you're looking into. My preference is always at least high-level summary, and deep-dive into challenger, blockers, opportunities, but you can choose what worrks best for you\n",
    "# 3. Create a .txt document called ApplicationWriter_CompanyContext.txt in the same folder of your Jupyter Notebook folder.\n",
    "# 4. Copy/paste your research into this document and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a61958f-0d45-4436-a3d2-1add19fe4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\\n\\n You are an amazing copywriter, expert in writing motivational letter that lands jobs. You are writing a fantastic motivational letter for <add your name>. She is applying to the role described in Website_scraper.txt. Use the experience provided in the input files to craft a masterful motivational letter that will land <your name> the job. Use the Application_Context.txt to highlight the challenges and possible opportunities, and suggest solutions for the blockers. The tone should be humble, enthusiastic, confident, and proactive. Audience: hiring manager. Goal: You want to show to the hiring manager Gaia understands the company like no-one else and she is perfect for the job. \\n\\n\"\n",
    "\n",
    "# This is the prompt to create your motivational letter. Add your name and adjust it as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "918f3ee1-5a7b-47a0-953d-545d6f242aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = LLM.invoke(examples + prompt + input + experience + context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f756a1f5-f8b5-4cef-8ac0-964397045c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Gaia Armellin**  \n",
      "[Your Address]  \n",
      "[City, State, Zip]  \n",
      "[Email]  \n",
      "[Phone Number]  \n",
      "[Date]  \n",
      "\n",
      "**Hiring Manager**  \n",
      "OMNIPEAK GmbH  \n",
      "[Company Address]  \n",
      "[City, State, Zip]  \n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am excited to submit my application for the Head of Product position at OMNIPEAK. With over 12 years of experience in strategic design, product leadership, and operational excellence, I am passionate about helping businesses navigate complex challenges while driving product innovation and fostering sustainable growth. OMNIPEAK's commitment to harnessing AI-powered solutions resonates deeply with my personal and professional ideals, and I am eager to contribute to its vision of revolutionizing the way marketing and sales teams operate.\n",
      "\n",
      "In my most recent role as Chapter Lead of UX for Customer Success at Backbase, I directed product strategy and UX design for a diverse portfolio of B2B SaaS solutions. Leading a high-performing team, I successfully crafted data-driven product roadmaps that aligned with company objectives—resulting in a notable increase in user satisfaction and engagement metrics. These experiences have honed my ability to leverage customer insights and user research to inform product priorities, ensuring that the solutions we develop not only meet market demands but also create lasting value for clients.\n",
      "\n",
      "OMNIPEAK's remote-first philosophy and culture of transparency, collaboration, and ambition are incredibly appealing to me. I thrive in agile environments and understand the importance of cultivating a strong team spirit—key elements that I have prioritized throughout my career. My leadership approach focuses on mentoring and empowering teams to achieve excellence, leveraging their unique talents to drive innovation. This aligns perfectly with OMNIPEAK’s commitment to building a world-class product organization and fostering a high-performance culture.\n",
      "\n",
      "I recognize that scaling products in fast-paced environments comes with its challenges, including ensuring product-market fit and operational efficiency. At Backbase, I led initiatives that optimized workflows and streamlined processes, achieving substantial cost reductions while enhancing overall team productivity. I believe these experiences equip me well to address the scaling challenges OMNIPEAK may encounter as it seeks to expand its market presence and refine its AI-driven offerings.\n",
      "\n",
      "Moreover, I am passionate about continuous improvement and experimentation. My commitment to sustainable practices and responsible innovation complements OMNIPEAK's mission to create impactful, meaningful products. I believe that by fostering a culture of curiosity and iteration, we can not only meet but exceed the expectations of our users, ultimately driving growth and success for the company.\n",
      "\n",
      "Thank you for considering my application. I am eager to bring my strategic mindset and enthusiasm for product development to OMNIPEAK and look forward to the opportunity to discuss how I can contribute to the growth and success of your innovative team. Let's create a future where AI-powered solutions empower teams to thrive!\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "Gaia Armellin  \n",
      "[LinkedIn Profile URL]  \n",
      "[Website URL]  \n"
     ]
    }
   ],
   "source": [
    "print(response.content)\n",
    "# print(type(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08e60e2-e0ec-4767-89f3-35107a774538",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Use capture_output as a context manager to capture prints\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m capture_output() \u001b[38;5;28;01mas\u001b[39;00m captured_output:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Save the captured output to a text file\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaptured_output._coverletter.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.utils.capture import capture_output\n",
    "\n",
    "# Use capture_output as a context manager to capture prints\n",
    "with capture_output() as captured_output:\n",
    "    print(response.content)\n",
    "\n",
    "# Save the captured output to a text file\n",
    "with open(\"captured_output._coverletter.txt\", \"w\") as file:\n",
    "    file.write(captured_output.stdout)\n",
    "\n",
    "print(\"The captured output has been saved to 'captured_output._coverletter.txt'\")\n",
    "\n",
    "\n",
    "#  captured_output._coverletter.txt will contain the motivational letter for the job post. Read it and edit as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1475f-bf6d-4d2b-8b18-d2ecc9fbd96f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
