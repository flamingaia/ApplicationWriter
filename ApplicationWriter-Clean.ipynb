{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69340398-bfd3-4b71-9ea4-20dc0d0ff5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "import langchain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6561931e-a0d5-48b7-a747-8ca530919d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /add your LLM key here (ChatGPT, LLama...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b5bb7-3e37-4dca-98a9-c8591da5cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "LLM = ChatOpenAI(\n",
    "    name=\"<recall key name here>\",\n",
    "    model=model_name,\n",
    "    # temperature=0, \n",
    "    temperature=1, \n",
    "    stop=[\"<|start_header_id|>\", \"<|end_header_id|>\", \"<|eot_id|>\", \"<|reserved_special_token\"]\n",
    ")\n",
    "\n",
    "# temperature=0 [strict and not creative output]\n",
    "#  temperature=1 [more creative output e.g. more empathic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbed2976-b3d9-4e9d-b6f7-fdb143830a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf2078d0-18ce-47f6-9f61-d3a360fdfd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('YourCV.txt', 'r') as g:\n",
    "    experience = g.read()\n",
    "\n",
    "# In the same folder of your Jupyter Notebook folder, create input document labeled YourCV.txt, containing your most recent CV and other details about your career and professional life in .txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0491db9-e61d-4f18-803f-cc722ea4ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Examples_JobApplications.txt', 'r') as f:\n",
    "    input = f.read()\n",
    "\n",
    "# In the same folder of your Jupyter Notebook folder, create input document labeled Examples_JobApplications.txt, containing examples of your previously written motivational letters in .txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "594e7b64-0e95-4f8d-8528-a24099d74cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added text from https://join.com/companies/omnipeak/13055016-head-of-product-m-f-d?pid=731067c1dfecf6015bf5&oid=1a7e3b62-65e7-44ba-8618-0add298db957\n",
      "All pages have been saved to Website_scraper_text.txt\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"<www.company.com/vacancy>\"\n",
    "    # Add here the URL of the vacancy or job opening you want to apply to\n",
    "]\n",
    "\n",
    "# Filename to save the combined text\n",
    "filename = \"Website_scraper_text.txt\"\n",
    "\n",
    "# Open the file in write mode to clear it if it exists\n",
    "with open(filename, \"w\") as file:\n",
    "    file.write(\"\")  # Start with an empty file\n",
    "\n",
    "# Loop through each URL\n",
    "for url in urls:\n",
    "    try:\n",
    "        # Step 1: Fetch the HTML content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Ensure request was successful\n",
    "        html_content = response.content\n",
    "\n",
    "        # Step 2: Parse the HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        \n",
    "        # Step 3: Extract the text\n",
    "        page_text = soup.get_text()\n",
    "\n",
    "        # Step 4: Append the extracted text to the file\n",
    "        with open(filename, \"a\") as file:\n",
    "            file.write(f\"URL: {url}\\n\")  # Optional: Write URL as a header\n",
    "            file.write(page_text)\n",
    "            file.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")  # Separator between pages\n",
    "\n",
    "        print(f\"Successfully added text from {url}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to retrieve {url}: {e}\")\n",
    "\n",
    "print(f\"All pages have been saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7453ca9b-cfe3-44fa-b41d-c80e3eecb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Website_scraper_text.txt', 'r') as f:\n",
    "    examples = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8687591e-02ea-4b0d-a630-261c47b6c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(examples)\n",
    "\n",
    "# If you want to double-check that the examples are right, then activate this code line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c0d2bd29-99f1-4907-bb09-ff2e66f14d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ApplicationWriter_CompanyContext.txt', 'r') as h:\n",
    "    context = h.read()\n",
    "\n",
    "# 1. Go to ChatGPT, Perplexity, Grok, or any other of your fav genAI platforms.\n",
    "# 2. Ask to run research on the company you're looking into. My preference is always at least high-level summary, and deep-dive into challenger, blockers, opportunities, but you can choose what worrks best for you\n",
    "# 3. Create a .txt document called ApplicationWriter_CompanyContext.txt in the same folder of your Jupyter Notebook folder.\n",
    "# 4. Copy/paste your research into this document and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a61958f-0d45-4436-a3d2-1add19fe4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\\n\\n You are an amazing copywriter, expert in writing motivational letter that lands jobs. You are writing a fantastic motivational letter for <add your name>. She is applying to the role described in Website_scraper.txt. Use the experience provided in the input files to craft a masterful motivational letter that will land <your name> the job. Use the Application_Context.txt to highlight the challenges and possible opportunities, and suggest solutions for the blockers. The tone should be humble, enthusiastic, confident, and proactive. Audience: hiring manager. Goal: You want to show to the hiring manager Gaia understands the company like no-one else and she is perfect for the job. \\n\\n\"\n",
    "\n",
    "# This is the prompt to create your motivational letter. Add your name and adjust it as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "918f3ee1-5a7b-47a0-953d-545d6f242aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = LLM.invoke(examples + prompt + input + experience + context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc80815-e67c-4b1e-81b2-cd813c7fcd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)\n",
    "# print(type(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1475f-bf6d-4d2b-8b18-d2ecc9fbd96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils.capture import capture_output\n",
    "\n",
    "# Use capture_output as a context manager to capture prints\n",
    "with capture_output() as captured_output:\n",
    "    print(response.content)\n",
    "\n",
    "# Save the captured output to a text file\n",
    "with open(\"captured_output._coverletter.txt\", \"w\") as file:\n",
    "    file.write(captured_output.stdout)\n",
    "\n",
    "print(\"The captured output has been saved to 'captured_output._coverletter.txt'\")\n",
    "\n",
    "\n",
    "#  captured_output._coverletter.txt will contain the motivational letter for the job post. Read it and edit as needed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
